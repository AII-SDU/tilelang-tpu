# TPU JIT é›†æˆä»£ç ä¿®æ”¹æ€»ç»“

æœ¬æ–‡æ¡£è¯¦ç»†è®°å½•äº†å¦‚ä½•åœ¨tilelangä¸­æ·»åŠ æ–°çš„targetï¼ˆTPUï¼‰ä»¥åŠå®ç°å®Œæ•´JITé›†æˆçš„æ ¸å¿ƒä»£ç ä¿®æ”¹ã€‚

## ğŸ¯ ä¿®æ”¹ç›®æ ‡

å°†TPUä»ç‹¬ç«‹çš„`@tpujit`è£…é¥°å™¨ç³»ç»Ÿé‡æ„ä¸ºä¸CUDA/HIPå®Œå…¨å…¼å®¹çš„æ ‡å‡†tilelang JITç³»ç»Ÿï¼Œå®ç°ç»Ÿä¸€çš„targetæ¶æ„ã€‚

## ğŸ“ æ ¸å¿ƒä»£ç ä¿®æ”¹

### 1. å¦‚ä½•æ·»åŠ æ–°çš„Targetæ”¯æŒ

#### æ­¥éª¤1: Targetå£°æ˜ - `tilelang/utils/target.py`
```python
# åŸä»£ç 
AVALIABLE_TARGETS = ["cuda", "hip"]

# ä¿®æ”¹å
AVALIABLE_TARGETS = ["cuda", "hip", "tpu"]
```
**ä½œç”¨**: å£°æ˜"tpu"ä¸ºåˆæ³•çš„targetå‚æ•°ï¼Œé€šè¿‡targetéªŒè¯æ£€æŸ¥ã€‚

#### æ­¥éª¤2: Loweré˜¶æ®µå¤„ç† - `tilelang/engine/lower.py`
**å…³é”®ä¿®æ”¹**: åœ¨lowerå‡½æ•°ä¸­æ·»åŠ TPUçš„ç‰¹æ®Šå¤„ç†é€»è¾‘
```python
# åœ¨lowerå‡½æ•°ä¸­æ·»åŠ ï¼ˆçº¦ç¬¬232è¡Œä½ç½®ï¼‰
# Special handling for TPU target which doesn't use TVM's target system
if (isinstance(target, str) and target == "tpu") or (hasattr(target, 'kind') and target.kind.name == "tpu"):
    # For TPU, use a dummy CPU target for TVM transforms but generate TPU code
    dummy_target = tvm.target.Target("llvm", tvm.target.Target("llvm"))
    
    # Phase 1: Lower and legalize the IR
    mod = LowerAndLegalize(mod, dummy_target)

    # Phase 2: Optimize the IR for the target  
    mod = OptimizeForTarget(mod, dummy_target)

    # Directly call TPU codegen and return source code
    device_source = tvm._ffi.get_global_func("target.build.tilelang_ppl")(mod)
    return CompiledArtifact(None, mod, params, device_source)
```
**æ ¸å¿ƒæ€æƒ³**: 
- TPUä¸ä½¿ç”¨TVMçš„æ ‡å‡†targetç³»ç»Ÿï¼Œè€Œæ˜¯ä½¿ç”¨è‡ªå·±çš„codegen
- ç”¨dummyçš„LLVM targetè¿›è¡ŒTVMå˜æ¢ï¼Œæœ€åè°ƒç”¨TPUä¸“ç”¨çš„codegenå‡½æ•°
- ç›´æ¥è¿”å›CompiledArtifactï¼Œç»•è¿‡æ ‡å‡†çš„TVMç¼–è¯‘æµç¨‹

**åˆ é™¤çš„æ—§ä»£ç **: åŸå…ˆç¬¬232è¡Œé™„è¿‘çš„hardcodedç‰¹æ®Šå¤„ç†é€»è¾‘

### 2. å¦‚ä½•å®ç°JITé›†æˆ

#### æ­¥éª¤3: JITç³»ç»Ÿé€‚é… - `tilelang/jit/__init__.py`

**å…³é”®ä¿®æ”¹1**: åœ¨`jit()`è£…é¥°å™¨å‡½æ•°ä¸­æ·»åŠ TPUè·¯ç”±
```python
# åœ¨jitå‡½æ•°ä¸­æ·»åŠ TPUæ£€æµ‹å’Œè·¯ç”±
if target == "tpu":
    from .adapter.tpu import TPUKernelAdapter
    adapter = TPUKernelAdapter(compiled_artifact, result_idx, fn_name)
    return TPUJITKernel(adapter)
```

**å…³é”®ä¿®æ”¹2**: åœ¨`compile()`APIå‡½æ•°ä¸­æ·»åŠ TPUè·¯ç”±
```python
# åœ¨compileå‡½æ•°ä¸­æ·»åŠ TPUæ”¯æŒ
if target == "tpu":
    from .adapter.tpu import TPUKernelAdapter
    adapter = TPUKernelAdapter(compiled_artifact, result_idx, fn_name)
    return TPUJITKernel(adapter)
```

**å…³é”®ä¿®æ”¹3**: åˆ›å»ºTPUä¸“ç”¨åŒ…è£…ç±»
```python
class TPUJITKernel:
    """TPU JITå†…æ ¸åŒ…è£…ç±»ï¼Œæä¾›ä¸CUDA/HIPç›¸åŒçš„æ¥å£"""
    def __init__(self, adapter):
        self.adapter = adapter
        
    def __getitem__(self, grid):
        """æ”¯æŒgridè¯­æ³•: kernel[(1,)](args)"""
        return self.adapter.__getitem__(grid)
        
    def __call__(self, *args):
        """æ”¯æŒç›´æ¥è°ƒç”¨: kernel(args)"""
        return self.adapter._convert_torch_func()(*args)
        
    def get_kernel_source(self) -> str:
        """è·å–å†…æ ¸æºç ï¼Œä¸CUDA/HIPæ¥å£ä¸€è‡´"""
        return self.adapter.get_kernel_source()
        
    def get_profiler(self, tensor_supply_type=None):
        """è·å–profilerï¼Œä¸CUDA/HIPæ¥å£ä¸€è‡´"""
        return self.adapter.get_profiler(tensor_supply_type)
```
**è®¾è®¡æ€æƒ³**: é€šè¿‡åŒ…è£…ç±»ç»Ÿä¸€æ¥å£ï¼Œä½¿TPU JITä¸CUDA/HIP JITå…·æœ‰å®Œå…¨ç›¸åŒçš„APIã€‚

### 3. æ ¸å¿ƒé€‚é…å™¨å®ç°

#### æ­¥éª¤4: åˆ›å»ºTPUé€‚é…å™¨ - `tilelang/jit/adapter/tpu.py` (æ–°æ–‡ä»¶)

**æ ¸å¿ƒè®¾è®¡**: å®ç°BaseKernelAdapteræ¥å£ï¼Œå¤„ç†TPUç‰¹æœ‰çš„ç¼–è¯‘å’Œæ‰§è¡Œé€»è¾‘

```python
class TPUKernelAdapter(BaseKernelAdapter):
    """TPUå†…æ ¸é€‚é…å™¨ï¼Œç»§æ‰¿æ ‡å‡†çš„BaseKernelAdapteræ¥å£"""
    
    def __init__(self, compiled_artifact: CompiledArtifact, result_idx: List[int], 
                 fn_name: str = None, chip: str = "bm1690"):
        super().__init__(compiled_artifact.device_mod, compiled_artifact.params, result_idx)
        self.compiled_artifact = compiled_artifact  # ä¿å­˜ç¼–è¯‘ç»“æœ
        self.fn_name = fn_name or "main"            # å†…æ ¸å‡½æ•°å
        self.result_idx = self._convert_negative_indices(result_idx, len(compiled_artifact.params))
```

**å…³é”®åŠŸèƒ½1**: å†…æ ¸ç¼–è¯‘å’Œç¼“å­˜ç³»ç»Ÿ
```python
def _prepare_shared_library(self):
    """å°†TPU Cä»£ç ç¼–è¯‘ä¸ºå…±äº«åº“ï¼Œå®ç°æ™ºèƒ½ç¼“å­˜"""
    # 1. ç”Ÿæˆæºä»£ç å“ˆå¸Œä½œä¸ºç¼“å­˜key
    hash_val = hashlib.md5(c_code.encode()).hexdigest()
    
    # 2. å¤„ç†TPUä¸“ç”¨å‡½æ•°åï¼ˆæ·»åŠ _kernelåç¼€ï¼‰
    kernel_fn_name = f"{self.fn_name}_kernel" if not self.fn_name.endswith("_kernel") else self.fn_name
    
    # 3. æ·»åŠ tensor_infoç»“æ„ä½“å®šä¹‰ï¼ˆTPUè¿è¡Œæ—¶éœ€è¦ï¼‰
    # 4. è°ƒç”¨SophGo TPUç¼–è¯‘å™¨ç”Ÿæˆå…±äº«åº“
    # 5. ç¼“å­˜ç¼–è¯‘ç»“æœï¼Œé¿å…é‡å¤ç¼–è¯‘
```

**å…³é”®åŠŸèƒ½2**: ä¸PyTorché›†æˆ
```python
def _convert_torch_func(self) -> Callable:
    """è½¬æ¢ä¸ºPyTorchå¯è°ƒç”¨å‡½æ•°ï¼Œå¤ç”¨æ ‡å‡†TileLangKernelæ‰§è¡Œé€»è¾‘"""
    # å®Œå…¨å¤åˆ¶BaseKernelAdapterçš„å‚æ•°å¤„ç†å’Œæ‰§è¡Œæµç¨‹
    # ä½¿ç”¨torch.ops.my_ops.dynlib_executeè°ƒç”¨TPUå…±äº«åº“
```

**å…³é”®åŠŸèƒ½3**: Profileræ¥å£é€‚é…
```python
def get_profiler(self, tensor_supply_type=None):
    """åˆ›å»ºTPUä¸“ç”¨profilerï¼Œè§£å†³è®¾å¤‡å…¼å®¹æ€§é—®é¢˜"""
    
    # é‡å†™å¼ é‡ä¾›åº”å‡½æ•°ï¼Œç”ŸæˆTPUè®¾å¤‡å¼ é‡
    def tpu_supply(param: KernelParam) -> torch.Tensor:
        import torch_tpu  # å¿…é¡»importæ‰èƒ½ä½¿ç”¨tpu:0è®¾å¤‡
        dtype: torch.dtype = param.dtype
        shape = tuple(int(s) for s in param.shape)
        device = "tpu:0"
        return torch.randn(*shape, device=device).to(dtype)
    
    # é‡å†™do_benchï¼Œå¤„ç†TPU simulatoré™åˆ¶
    def tpu_aware_do_bench(func=None, warmup=25, rep=100, n_warmup=1, n_repeat=1, input_tensors=None):
        print(f"æ³¨æ„: TPU simulatoré™åˆ¶ï¼Œå»ºè®®ä½¿ç”¨è¾ƒå°å‚æ•°é¿å…å´©æºƒ")
        return original_do_bench(func, warmup, rep, n_warmup, n_repeat, input_tensors)
```

**å…³é”®åŠŸèƒ½4**: è‡ªåŠ¨ç¯å¢ƒé…ç½®
```python
def _auto_source_sophgo_env():
    """è‡ªåŠ¨åŠ è½½SophGo TPUç¯å¢ƒå˜é‡"""
    # è§£æenvsetup.shå¹¶è®¾ç½®ç¯å¢ƒå˜é‡
    # ç¡®ä¿TPUç¼–è¯‘å™¨å’Œè¿è¡Œæ—¶æ­£ç¡®åŠ è½½
```

## ğŸ”§ å…³é”®æŠ€æœ¯è§£å†³æ–¹æ¡ˆ

### 1. å‡½æ•°åå¤„ç†
**é—®é¢˜**: TPUå†…æ ¸éœ€è¦è°ƒç”¨`_kernel`åç¼€çš„wrapperå‡½æ•°  
**è§£å†³**: åœ¨ç¼–è¯‘è¿‡ç¨‹ä¸­è‡ªåŠ¨æ·»åŠ `_kernel`åç¼€
```python
kernel_fn_name = f"{self.fn_name}_kernel" if not self.fn_name.endswith("_kernel") else self.fn_name
```

### 2. è®¾å¤‡å…¼å®¹æ€§
**é—®é¢˜**: Profileré»˜è®¤ç”ŸæˆCUDAå¼ é‡ï¼Œä½†TPUéœ€è¦TPUè®¾å¤‡å¼ é‡  
**è§£å†³**: åˆ›å»ºTPUä¸“ç”¨çš„å¼ é‡ä¾›åº”å‡½æ•°
```python
def tpu_supply(param: KernelParam) -> torch.Tensor:
    import torch_tpu
    dtype: torch.dtype = param.dtype
    shape = tuple(int(s) for s in param.shape)
    device = "tpu:0"
    return torch.randn(*shape, device=device).to(dtype)
```

### 3. ç¼–è¯‘ç¼“å­˜
**é—®é¢˜**: é‡å¤ç¼–è¯‘æµªè´¹æ—¶é—´  
**è§£å†³**: åŸºäºæºä»£ç å“ˆå¸Œçš„ç¼“å­˜æœºåˆ¶
```python
hash_val = hashlib.md5(c_code.encode()).hexdigest()
cache_dir = os.path.join(os.getcwd(), ".tilelang_cache")
```

### 4. Profiler do_benché™åˆ¶
**é—®é¢˜**: TPU simulatorå¯¹é‡å¤æ‰§è¡Œæœ‰é™åˆ¶  
**è§£å†³**: ä¿æŒæ¥å£å…¼å®¹ï¼Œå†…éƒ¨å¤„ç†é™åˆ¶
```python
def tpu_aware_do_bench(func=None, warmup=25, rep=100, n_warmup=1, n_repeat=1, input_tensors=None):
    print(f"æ³¨æ„: TPU simulatoré™åˆ¶ï¼Œå»ºè®®ä½¿ç”¨è¾ƒå°å‚æ•°é¿å…å´©æºƒ")
    return original_do_bench(func, warmup, rep, n_warmup, n_repeat, input_tensors)
```

## ğŸ“ ç¤ºä¾‹æ–‡ä»¶ä¿®æ”¹

å°†ç°æœ‰çš„pplç¤ºä¾‹ä¿®æ”¹ä¸ºæ ‡å‡†JITæ ¼å¼ï¼š

### 1. è£…é¥°å™¨æ–¹å¼ (reduce_max)
```python
# åŸæ¥: ä½¿ç”¨tilelang.lower
func = reduce_max(8192, 1020, 512, 1020)
mod = tilelang.lower(func)

# ç°åœ¨: ä½¿ç”¨è£…é¥°å™¨
@tilelang.jit(target="tpu", out_idx=[-1])
@T.prim_func
def reduce_max(X: T.Tensor((8192, 1020), "float32"), Y: T.Tensor((8192, 1), "float32")):
    # å†…æ ¸å®ç°
    pass

# è°ƒç”¨
reduce_max[(1,)](input_tensor, output_tensor)
```

### 2. ç¼–è¯‘APIæ–¹å¼ (reduce_sum, matmul)
```python
# åŸæ¥: ä½¿ç”¨tilelang.lower
func = reduce_sum(8192, 8192, 512, 8192)
mod = tilelang.lower(func)

# ç°åœ¨: ä½¿ç”¨ç¼–è¯‘API
@T.prim_func
def reduce_sum_func(X: T.Tensor((8192, 8192), "float32"), Y: T.Tensor((8192, 1), "float32")):
    # å†…æ ¸å®ç°
    pass

# ç¼–è¯‘å’Œè°ƒç”¨
reduce_sum = tilelang.compile(reduce_sum_func, target="tpu", out_idx=[-1])
reduce_sum[(1,)](input_tensor, output_tensor)
```

## âœ… å®ç°çš„åŠŸèƒ½

### 1. å®Œå…¨æ¥å£å…¼å®¹
- `@tilelang.jit(target="tpu", out_idx=[-1])` - è£…é¥°å™¨æ–¹å¼
- `tilelang.compile(func, target="tpu", out_idx=[-1])` - ç¼–è¯‘APIæ–¹å¼
- `kernel[(grid,)](args)` - Gridè¯­æ³•æ”¯æŒ
- `kernel(args)` - ç›´æ¥è°ƒç”¨æ”¯æŒ

### 2. Profilerå®Œæ•´æ”¯æŒ
- `kernel.get_kernel_source()` - è·å–Cæºç 
- `kernel.get_profiler()` - åˆ›å»ºæ€§èƒ½åˆ†æå™¨
- `profiler._get_inputs()` - è‡ªåŠ¨ç”ŸæˆTPUè®¾å¤‡å¼ é‡
- `profiler.run_once()` - å•æ¬¡æ‰§è¡Œæµ‹è¯•
- `profiler.do_bench()` - æ€§èƒ½åŸºå‡†æµ‹è¯•
- `profiler(*args)` - ç›´æ¥è°ƒç”¨

### 3. è‡ªåŠ¨åŒ–åŠŸèƒ½
- è‡ªåŠ¨ç¯å¢ƒå˜é‡åŠ è½½
- è‡ªåŠ¨ç¼–è¯‘ç¼“å­˜
- è‡ªåŠ¨å‡½æ•°åå¤„ç†
- è‡ªåŠ¨è®¾å¤‡å¼ é‡ç”Ÿæˆ

## ğŸ‰ æœ€ç»ˆæˆæœ

1. **æ¥å£ç»Ÿä¸€**: TPU JITä¸CUDA/HIP JITä½¿ç”¨å®Œå…¨ç›¸åŒçš„æ¥å£
2. **ä»£ç å¤ç”¨**: ç”¨æˆ·ä»£ç åœ¨ä¸åŒtargeté—´æ— ç¼åˆ‡æ¢
3. **å‘åå…¼å®¹**: ä¸å½±å“ç°æœ‰CUDA/HIP JITåŠŸèƒ½
4. **å®Œæ•´åŠŸèƒ½**: æ”¯æŒæ‰€æœ‰æ ‡å‡†JITåŠŸèƒ½ï¼ŒåŒ…æ‹¬profiler

## ğŸ“Š æµ‹è¯•éªŒè¯

åˆ›å»ºäº†å®Œæ•´çš„æµ‹è¯•ç”¨ä¾‹ï¼š
- `tpu_demo/ppl/reduce_max_kernel/reduce_max.py` - è£…é¥°å™¨æ–¹å¼æµ‹è¯•
- `tpu_demo/ppl/reduce_sum_kernel/reduce_sum.py` - ç¼–è¯‘APIæ–¹å¼æµ‹è¯•  
- `tpu_demo/ppl/matmul_kernel/matmul.py` - ç¼–è¯‘APIæ–¹å¼æµ‹è¯•
- `tpu_demo/test_all_jit.py` - å…¨é¢æµ‹è¯•è„šæœ¬

æ‰€æœ‰æµ‹è¯•éƒ½åŒ…å«ï¼š
- åŠŸèƒ½æ­£ç¡®æ€§éªŒè¯
- ä¸PyTorchåŸç”Ÿå®ç°å¯¹æ¯”
- Profileræ¥å£éªŒè¯
- è®¾å¤‡å…¼å®¹æ€§æ£€æŸ¥

## ğŸš€ ä½¿ç”¨æ–¹æ³•

```python
# ç°åœ¨ç”¨æˆ·å¯ä»¥æ— ç¼åˆ‡æ¢target
@tilelang.jit(target="cuda", out_idx=[-1])  # CUDAç‰ˆæœ¬
# @tilelang.jit(target="hip", out_idx=[-1])   # HIPç‰ˆæœ¬  
# @tilelang.jit(target="tpu", out_idx=[-1])   # TPUç‰ˆæœ¬
@T.prim_func
def my_kernel(X, Y):
    # ç›¸åŒçš„å†…æ ¸ä»£ç 
    pass

# ç›¸åŒçš„è°ƒç”¨æ–¹å¼
my_kernel[(1,)](input_tensor, output_tensor)

# ç›¸åŒçš„profileræ¥å£
profiler = my_kernel.get_profiler()
```

è¿™æ ‡å¿—ç€TPU JITå®Œå…¨é›†æˆåˆ°tilelangæ ‡å‡†æ¶æ„ä¸­ï¼Œå®ç°äº†çœŸæ­£çš„ç»Ÿä¸€ï¼